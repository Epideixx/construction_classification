{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "mpl.style.use('seaborn')\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"preprocessed_train_2.csv\", index_col=\"index\")\n",
    "\n",
    "train_set[\"change_type\"] = train_set[\"change_type\"].map({'Demolition': 0, 'Road': 1, 'Residential': 2, 'Commercial': 3, 'Industrial': 4,\n",
    "       'Mega Projects': 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['change_type'] = train_set['change_type'].apply(lambda x: 4 if x == 5 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    164120\n",
       "3     99462\n",
       "0     29738\n",
       "1     15020\n",
       "4      1666\n",
       "Name: change_type, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['change_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_set.drop(columns=[\"change_type\"])\n",
    "y = train_set[\"change_type\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> LightGBM Based Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "model = LGBMClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.76      0.84      9031\n",
      "           1       0.64      0.77      0.70      3200\n",
      "           2       0.82      0.80      0.81     41934\n",
      "           3       0.64      0.69      0.66     23221\n",
      "           4       0.07      0.25      0.11       116\n",
      "\n",
      "    accuracy                           0.76     77502\n",
      "   macro avg       0.62      0.65      0.62     77502\n",
      "weighted avg       0.77      0.76      0.76     77502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(model.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.73      0.83      9690\n",
      "           1       0.85      0.47      0.61      6818\n",
      "           2       0.68      0.86      0.76     32566\n",
      "           3       0.63      0.63      0.63     24894\n",
      "           4       0.65      0.07      0.13      3534\n",
      "\n",
      "    accuracy                           0.70     77502\n",
      "   macro avg       0.75      0.55      0.59     77502\n",
      "weighted avg       0.71      0.70      0.68     77502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model2 = LGBMClassifier(class_weight=\"balanced\").fit(X_train, y_train)\n",
    "print(classification_report(model2.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def lgb_f1_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n",
    "    return 'f1', f1_score(y_true, y_hat,average='macro'), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "def lgb_recall_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n",
    "    return 'recall', recall_score(y_true, y_hat,average='macro'), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['change_type'] = train_set['change_type'].apply(lambda x: 0 if x in [0, 1, 2, 3] else 1)\n",
    "\n",
    "X = train_set.drop(columns=[\"change_type\"])\n",
    "y = train_set[\"change_type\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    308340\n",
       "1      1666\n",
       "Name: change_type, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     77187\n",
      "           1       0.16      0.23      0.19       315\n",
      "\n",
      "    accuracy                           0.99     77502\n",
      "   macro avg       0.58      0.61      0.59     77502\n",
      "weighted avg       0.99      0.99      0.99     77502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model3 = LGBMClassifier(metric = \"lgb_recall_score\", class_weight={0:2, 1:10}).fit(X_train, y_train)\n",
    "print(classification_report(model3.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     77428\n",
      "           1       0.01      0.08      0.02        74\n",
      "\n",
      "    accuracy                           0.99     77502\n",
      "   macro avg       0.51      0.54      0.51     77502\n",
      "weighted avg       1.00      0.99      1.00     77502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model4 = LGBMClassifier(class_weight={0:100, 1:1}).fit(X_train, y_train)\n",
    "print(classification_report(model4.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bon il faut se démerder pour augmenter le recall de la classe 4-5 de ouf sans chuter la précision..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Keras Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def f1_weighted(true, pred): #shapes (batch, 4)\n",
    "\n",
    "    return 1 - f1_score(true, pred) #for metrics, return only 'weighted_f1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model_net = Sequential([\n",
    "    Dense(512, activation = \"sigmoid\", input_shape = [np.shape(X_train)[1]]),\n",
    "    Dense(512, activation = \"sigmoid\"),\n",
    "    Dense(256, activation = \"sigmoid\"),\n",
    "    Dense(5, activation = \"sigmoid\")\n",
    "])\n",
    "\n",
    "model_net.compile(optimizer = \"rmsprop\", loss = \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "727/727 [==============================] - 15s 20ms/step - loss: 0.0360 - accuracy: 0.9933 - val_loss: 0.0324 - val_accuracy: 0.9950\n",
      "Epoch 2/10\n",
      "727/727 [==============================] - 13s 18ms/step - loss: 0.0335 - accuracy: 0.9947 - val_loss: 0.0315 - val_accuracy: 0.9950\n",
      "Epoch 3/10\n",
      "727/727 [==============================] - 13s 18ms/step - loss: 0.0335 - accuracy: 0.9947 - val_loss: 0.0316 - val_accuracy: 0.9950\n",
      "Epoch 4/10\n",
      "727/727 [==============================] - 13s 18ms/step - loss: 0.0335 - accuracy: 0.9947 - val_loss: 0.0314 - val_accuracy: 0.9950\n",
      "Epoch 5/10\n",
      "727/727 [==============================] - 13s 18ms/step - loss: 0.0335 - accuracy: 0.9947 - val_loss: 0.0315 - val_accuracy: 0.9950\n",
      "Epoch 6/10\n",
      "727/727 [==============================] - 14s 19ms/step - loss: 0.0335 - accuracy: 0.9947 - val_loss: 0.0315 - val_accuracy: 0.9950\n",
      "Epoch 7/10\n",
      "727/727 [==============================] - 13s 18ms/step - loss: 0.0335 - accuracy: 0.9947 - val_loss: 0.0316 - val_accuracy: 0.9950\n",
      "Epoch 8/10\n",
      "727/727 [==============================] - 13s 17ms/step - loss: 0.0334 - accuracy: 0.9947 - val_loss: 0.0316 - val_accuracy: 0.9950\n",
      "Epoch 9/10\n",
      "727/727 [==============================] - 13s 18ms/step - loss: 0.0334 - accuracy: 0.9947 - val_loss: 0.0316 - val_accuracy: 0.9950\n",
      "Epoch 10/10\n",
      "727/727 [==============================] - 12s 17ms/step - loss: 0.0335 - accuracy: 0.9947 - val_loss: 0.0320 - val_accuracy: 0.9950\n"
     ]
    }
   ],
   "source": [
    "history = model_net.fit(X_train, y_train, batch_size = 256, epochs = 10, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 2, ..., 2, 3, 2], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model_net.predict(X_test), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     77502\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.99     77502\n",
      "   macro avg       0.50      0.50      0.50     77502\n",
      "weighted avg       1.00      0.99      1.00     77502\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(model_net.predict(X_test), axis = 1), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[77061,   441],\n",
       "       [    0,     0]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(np.argmax(model_net.predict(X_test), axis = 1), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    77061\n",
       "1      441\n",
       "Name: change_type, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> New complex model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    123333\n",
       "3     74508\n",
       "0     22175\n",
       "1     11236\n",
       "4      1252\n",
       "Name: change_type, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "def new_sampling(X, y, strategy):\n",
    "    strat_under = {}\n",
    "\n",
    "    for cat, nb in strategy.items():\n",
    "        if nb < np.unique(y, return_counts=True)[1][cat]:\n",
    "            strat_under[cat] = nb\n",
    "        else : \n",
    "            strat_under[cat] = np.unique(y, return_counts=True)[1][cat]\n",
    "    X, y = RandomUnderSampler(sampling_strategy=strat_under).fit_resample(X, y)\n",
    "    X, y = RandomOverSampler(sampling_strategy=strategy).fit_resample(X, y)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we are going to make some Under and Over Sampling\n",
    "\n",
    "strategy = {0 : 40000, 1 : 40000, 2 : 70000, 3 : 50000, 4 : 30000} # L'adapter pour ne pas le faire à la main !!!\n",
    "\n",
    "X_train_new, y_train_new = new_sampling(X_train, y_train, strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.78      0.82      8399\n",
      "           1       0.64      0.77      0.70      3153\n",
      "           2       0.73      0.84      0.78     35528\n",
      "           3       0.75      0.63      0.68     29707\n",
      "           4       0.32      0.19      0.24       715\n",
      "\n",
      "    accuracy                           0.74     77502\n",
      "   macro avg       0.66      0.64      0.65     77502\n",
      "weighted avg       0.75      0.74      0.74     77502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_comp = LGBMClassifier(class_weight={0:1, 1:3, 2:2, 3:3, 4:17}).fit(X_train, y_train)\n",
    "print(classification_report(model_comp.predict(X_test), y_test))\n",
    "\n",
    "# IDEE : Faire un GridSearch sur les class_weight\n",
    "# C'est pas trop mal en vraiii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6551    21  1320   498     9]\n",
      " [   24  2427   205   489     8]\n",
      " [  321   204 29945  4959    99]\n",
      " [  655  1102  9131 18655   164]\n",
      " [   12    30   186   353   134]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(model_comp.predict(X_test), y_test))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "92237062529a7dfad5db2170781e2ae2a26d776f3e84984f0f74275a2cb5ec83"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
