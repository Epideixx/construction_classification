{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14196/2637782860.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'geopandas'"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from feature_engine.creation import CyclicalTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_type_map = {'Demolition': 0, 'Road': 1, 'Residential': 2, 'Commercial': 3, 'Industrial': 4,\n",
    "       'Mega Projects': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read csvs\n",
    "\n",
    "train_df_init = gpd.read_file('train.geojson', index_col=0)\n",
    "test_df_init = gpd.read_file('test.geojson', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Copying them\n",
    "train_df = train_df_init.copy(deep=True)\n",
    "test_df = test_df_init.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>change_type</th>\n",
       "      <th>change_status_date1</th>\n",
       "      <th>change_status_date2</th>\n",
       "      <th>change_status_date3</th>\n",
       "      <th>change_status_date4</th>\n",
       "      <th>change_status_date5</th>\n",
       "      <th>date1</th>\n",
       "      <th>date2</th>\n",
       "      <th>date3</th>\n",
       "      <th>date4</th>\n",
       "      <th>date5</th>\n",
       "      <th>urban_types</th>\n",
       "      <th>geography_types</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Land Cleared</td>\n",
       "      <td>Construction Midway</td>\n",
       "      <td>Construction Done</td>\n",
       "      <td>Construction Done</td>\n",
       "      <td>Construction Done</td>\n",
       "      <td>29-05-2014</td>\n",
       "      <td>13-09-2015</td>\n",
       "      <td>25-02-2017</td>\n",
       "      <td>10-10-2018</td>\n",
       "      <td>19-05-2020</td>\n",
       "      <td>Industrial</td>\n",
       "      <td>River,Sparse Forest,Grass Land</td>\n",
       "      <td>POLYGON ((116.97563 38.89002, 116.97590 38.890...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Greenland</td>\n",
       "      <td>Greenland</td>\n",
       "      <td>Construction Done</td>\n",
       "      <td>Construction Done</td>\n",
       "      <td>Construction Done</td>\n",
       "      <td>29-05-2014</td>\n",
       "      <td>13-09-2015</td>\n",
       "      <td>25-02-2017</td>\n",
       "      <td>10-10-2018</td>\n",
       "      <td>19-05-2020</td>\n",
       "      <td>Sparse Urban</td>\n",
       "      <td>Sparse Forest,Grass Land</td>\n",
       "      <td>POLYGON ((116.97500 38.88969, 116.97524 38.889...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Land Cleared</td>\n",
       "      <td>Land Cleared</td>\n",
       "      <td>Construction Done</td>\n",
       "      <td>Construction Done</td>\n",
       "      <td>Construction Done</td>\n",
       "      <td>29-05-2014</td>\n",
       "      <td>13-09-2015</td>\n",
       "      <td>25-02-2017</td>\n",
       "      <td>10-10-2018</td>\n",
       "      <td>19-05-2020</td>\n",
       "      <td>Sparse Urban</td>\n",
       "      <td>Sparse Forest,Grass Land</td>\n",
       "      <td>POLYGON ((116.97519 38.88847, 116.97568 38.888...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Land Cleared</td>\n",
       "      <td>Land Cleared</td>\n",
       "      <td>Construction Midway</td>\n",
       "      <td>Construction Midway</td>\n",
       "      <td>Construction Done</td>\n",
       "      <td>29-05-2014</td>\n",
       "      <td>13-09-2015</td>\n",
       "      <td>25-02-2017</td>\n",
       "      <td>10-10-2018</td>\n",
       "      <td>19-05-2020</td>\n",
       "      <td>Industrial</td>\n",
       "      <td>River,Sparse Forest,Grass Land</td>\n",
       "      <td>POLYGON ((116.97630 38.89017, 116.97730 38.890...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Land Cleared</td>\n",
       "      <td>Land Cleared</td>\n",
       "      <td>Construction Started</td>\n",
       "      <td>Construction Midway</td>\n",
       "      <td>Construction Done</td>\n",
       "      <td>29-05-2014</td>\n",
       "      <td>13-09-2015</td>\n",
       "      <td>25-02-2017</td>\n",
       "      <td>10-10-2018</td>\n",
       "      <td>19-05-2020</td>\n",
       "      <td>Industrial</td>\n",
       "      <td>River,Sparse Forest,Grass Land</td>\n",
       "      <td>POLYGON ((116.97751 38.89037, 116.97854 38.890...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index change_type change_status_date1  change_status_date2  \\\n",
       "0      0  Commercial        Land Cleared  Construction Midway   \n",
       "1      1  Commercial           Greenland            Greenland   \n",
       "2      2  Commercial        Land Cleared         Land Cleared   \n",
       "3      3  Commercial        Land Cleared         Land Cleared   \n",
       "4      4  Commercial        Land Cleared         Land Cleared   \n",
       "\n",
       "    change_status_date3  change_status_date4 change_status_date5       date1  \\\n",
       "0     Construction Done    Construction Done   Construction Done  29-05-2014   \n",
       "1     Construction Done    Construction Done   Construction Done  29-05-2014   \n",
       "2     Construction Done    Construction Done   Construction Done  29-05-2014   \n",
       "3   Construction Midway  Construction Midway   Construction Done  29-05-2014   \n",
       "4  Construction Started  Construction Midway   Construction Done  29-05-2014   \n",
       "\n",
       "        date2       date3       date4       date5   urban_types  \\\n",
       "0  13-09-2015  25-02-2017  10-10-2018  19-05-2020    Industrial   \n",
       "1  13-09-2015  25-02-2017  10-10-2018  19-05-2020  Sparse Urban   \n",
       "2  13-09-2015  25-02-2017  10-10-2018  19-05-2020  Sparse Urban   \n",
       "3  13-09-2015  25-02-2017  10-10-2018  19-05-2020    Industrial   \n",
       "4  13-09-2015  25-02-2017  10-10-2018  19-05-2020    Industrial   \n",
       "\n",
       "                  geography_types  \\\n",
       "0  River,Sparse Forest,Grass Land   \n",
       "1        Sparse Forest,Grass Land   \n",
       "2        Sparse Forest,Grass Land   \n",
       "3  River,Sparse Forest,Grass Land   \n",
       "4  River,Sparse Forest,Grass Land   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((116.97563 38.89002, 116.97590 38.890...  \n",
       "1  POLYGON ((116.97500 38.88969, 116.97524 38.889...  \n",
       "2  POLYGON ((116.97519 38.88847, 116.97568 38.888...  \n",
       "3  POLYGON ((116.97630 38.89017, 116.97730 38.890...  \n",
       "4  POLYGON ((116.97751 38.89037, 116.97854 38.890...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Area for geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raphaelhaddad/.local/lib/python3.8/site-packages/geopandas/geodataframe.py:1350: UserWarning: Geometry column does not contain geometry.\n",
      "  warnings.warn(\"Geometry column does not contain geometry.\")\n",
      "/home/raphaelhaddad/.local/lib/python3.8/site-packages/geopandas/geodataframe.py:1350: UserWarning: Geometry column does not contain geometry.\n",
      "  warnings.warn(\"Geometry column does not contain geometry.\")\n"
     ]
    }
   ],
   "source": [
    "## Handling area value (We can choose something else)\n",
    "train_df['geometry'] = train_df['geometry'].map(lambda a: a.area)\n",
    "test_df['geometry'] = test_df['geometry'].map(lambda a: a.area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> One Hot encoding Urban types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = \"urban_types\"\n",
    "class_maping = {label: idx for idx, label in enumerate(np.unique(train_df[feature]))}\n",
    "\n",
    "# Careful : 15 different classes\n",
    "\n",
    "X_train_urban = train_df[[feature]]\n",
    "X_test_urban = test_df[[feature]]\n",
    "X_train_urban = pd.get_dummies(X_train_urban)\n",
    "X_test_urban = pd.get_dummies(X_test_urban)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop the old urban_type column and replacing it with the one hot encoding\n",
    "feature = \"urban_types\"\n",
    "train_df = pd.concat([train_df.drop([feature], axis=1), X_train_urban], sort=False, axis=1)\n",
    "test_df = pd.concat([test_df.drop([feature], axis=1), X_test_urban], sort=False, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> One Hot encoding geography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Barren Land', 'Dense Forest', 'Grass Land']\n",
      "{'Hills', 'None', 'River', 'Dense Forest', 'Barren Land', 'Snow', 'Farms', 'Desert', 'Lakes', 'Coastal', 'Sparse Forest', 'Grass Land'}\n"
     ]
    }
   ],
   "source": [
    "feature = \"geography_types\"\n",
    "class_maping = {label: idx for idx, label in enumerate(np.unique(train_df[feature]))}\n",
    "## Way too many class : not one-hot encoding : https://stats.stackexchange.com/questions/411767/encoding-of-categorical-variables-with-high-cardinality\n",
    "\n",
    "all_geography = np.unique(train_df[feature])\n",
    "print(all_geography[4].split(','))\n",
    "visited=set()\n",
    "for word_list in all_geography :\n",
    "    word_list = word_list.split(',')\n",
    "    for word in word_list :\n",
    "        visited.add(word)\n",
    "print(visited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the one hot-encoding for lists\n",
    "feature = \"geography_types\"\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "geo_train = train_df[feature]\n",
    "geo_train = geo_train.map(lambda geo_list: geo_list.split(','))\n",
    "geo_test = test_df[feature]\n",
    "geo_test = geo_test.map(lambda geo_list: geo_list.split(','))\n",
    "\n",
    "geo_train = pd.DataFrame(mlb.fit_transform(geo_train),columns=mlb.classes_, index=geo_train.index)\n",
    "geo_test = pd.DataFrame(mlb.fit_transform(geo_test),columns=mlb.classes_, index=geo_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop the old geography type column and replacing it with the one hot encoding\n",
    "feature = \"geography_types\"\n",
    "train_df = pd.concat([train_df.drop([feature], axis=1), geo_train], sort=False, axis=1)\n",
    "test_df = pd.concat([test_df.drop([feature], axis=1), geo_test], sort=False, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Handling date columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = \"date1\"\n",
    "class_maping = {label: idx for idx, label in enumerate(np.unique(train_df[feature]))}\n",
    "\n",
    "\n",
    "## More than 210 first date\n",
    "## Need to find a there is a correlation\n",
    "## Separate Year, month and day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fetch all date datas in a dictionary\n",
    "dates = [\"date1\", \"date2\", \"date3\", \"date4\", \"date5\"]\n",
    "train_date_dic = {}\n",
    "test_date_dic = {}\n",
    "for date in dates :\n",
    "    train_date_dic[\"train_%s\" % date] = train_df[date]\n",
    "    test_date_dic[\"test_%s\" % date] = test_df[date]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a year, month and day dataframe for each date\n",
    "train_dates = [\"train_date1\", \"train_date2\", \"train_date3\", \"train_date4\", \"train_date5\"]\n",
    "test_dates = [\"test_date1\", \"test_date2\", \"test_date3\", \"test_date4\", \"test_date5\"]\n",
    "\n",
    "train_year_dic = {}\n",
    "train_month_dic = {}\n",
    "train_day_dic = {}\n",
    "test_year_dic = {}\n",
    "test_month_dic = {}\n",
    "test_day_dic = {}\n",
    "\n",
    "for i in range(5) :\n",
    "    train_year_dic[\"train_year%s\" % str(i+1)] = train_date_dic[train_dates[i]].map(lambda a: int(a[6:10])).rename(\"year%s\" % str(i+1))\n",
    "    train_month_dic[\"train_month%s\" % str(i+1)] = train_date_dic[train_dates[i]].map(lambda a: int(a[3:5])).rename(\"month%s\" % str(i+1))\n",
    "    train_day_dic[\"train_day%s\" % str(i+1)] = train_date_dic[train_dates[i]].map(lambda a: int(a[0:2])).rename(\"day%s\" % str(i+1))\n",
    "\n",
    "    test_year_dic[\"test_year%s\" % str(i+1)] = test_date_dic[test_dates[i]].map(lambda a: int(a[6:10])).rename(\"year%s\" % str(i+1))\n",
    "    test_month_dic[\"test_month%s\" % str(i+1)] = test_date_dic[test_dates[i]].map(lambda a: int(a[3:5])).rename(\"month%s\" % str(i+1))\n",
    "    test_day_dic[\"test_day%s\" % str(i+1)] = test_date_dic[test_dates[i]].map(lambda a: int(a[0:2])).rename(\"day%s\" % str(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can drop date columns and add these day - month - year column\n",
    "dates = [\"date1\", \"date2\", \"date3\", \"date4\", \"date5\"]\n",
    "for date in dates :\n",
    "    train_df = train_df.drop([date], axis=1)\n",
    "    test_df = test_df.drop([date], axis=1)\n",
    "    \n",
    "for i in range(1, 6):\n",
    "    train_df = pd.concat([train_df, train_year_dic[\"train_year%s\" % str(i)]], sort=False, axis=1)\n",
    "    train_df = pd.concat([train_df, train_month_dic[\"train_month%s\" % str(i)]], sort=False, axis=1)\n",
    "    train_df = pd.concat([train_df, train_day_dic[\"train_day%s\" % str(i)]], sort=False, axis=1)\n",
    "\n",
    "    test_df = pd.concat([test_df, test_year_dic[\"test_year%s\" % str(i)]], sort=False, axis=1)\n",
    "    test_df = pd.concat([test_df, test_month_dic[\"test_month%s\" % str(i)]], sort=False, axis=1)\n",
    "    test_df = pd.concat([test_df, test_day_dic[\"test_day%s\" % str(i)]], sort=False, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Month and day can't be used like this. \n",
    "## We need to add a cyclical variable sin and cos\n",
    "## https://stats.stackexchange.com/questions/311494/best-practice-for-encoding-datetime-in-machine-learning\n",
    "\n",
    "variables = []\n",
    "numbers = [i for i in range(1, 6)]\n",
    "time_variables = [\"month\", \"day\"]\n",
    "\n",
    "for number in numbers :\n",
    "    for time_variable in time_variables :\n",
    "        variables.append(\"%s%s\" % (time_variable, number))\n",
    "\n",
    "## Issue with the transform method : need to have same number of column\n",
    "## Solution : drop first column of train_df and add it after\n",
    "\n",
    "cyclical = CyclicalTransformer(variables=variables, drop_original=True)\n",
    "train_change_type_column = train_df[\"change_type\"]\n",
    "train_df = train_df.drop([\"change_type\"], axis=1)\n",
    "\n",
    "train_df = cyclical.fit_transform(train_df)\n",
    "test_df = cyclical.transform(test_df)\n",
    "\n",
    "## Adding the dropped column\n",
    "\n",
    "train_df = pd.concat([train_change_type_column, train_df], sort=False, axis=1)\n",
    "\n",
    "## Last step : changing the order of columns to have the inital order\n",
    "first_column = train_df.pop('index')\n",
    "train_df.insert(0, 'index', first_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Last Step : Handling change_status_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = \"change_status_date4\"\n",
    "class_maping = {label: idx for idx, label in enumerate(np.unique(train_df[feature]))}\n",
    "\n",
    "## 9 class labels for each columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## One-hot-encoding for each columns\n",
    "change_status_columns = [\"change_status_date1\", \"change_status_date2\", \"change_status_date3\", \"change_status_date4\", \"change_status_date5\"]\n",
    "\n",
    "for feature in change_status_columns :\n",
    "\n",
    "    X_train_status = train_df[[feature]]\n",
    "    X_test_status = test_df[[feature]]\n",
    "    X_train_status = pd.get_dummies(X_train_status)\n",
    "    X_test_status = pd.get_dummies(X_test_status)\n",
    "\n",
    "    train_df = pd.concat([train_df.drop([feature], axis=1), X_train_status], sort=False, axis=1)\n",
    "    test_df = pd.concat([test_df.drop([feature], axis=1), X_test_status], sort=False, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Save the dataframe as a csv and json on the hard disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"preprocessed_train.csv\", index=True, index_label='Id')\n",
    "test_df.to_csv(\"preprocessed_test.csv\", index=True, index_label='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Preparation and reduction of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The next goal is to choose the best features. Use the countless methode \n",
    "# like PCA and other reduction method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building a model a the smaller dataset. When the model is strong \n",
    "# with few features, add other features + Hyperparameter Tuning"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
