{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "mpl.style.use('seaborn')\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the csv files\n",
    "\n",
    "train_data = pd.read_csv(\"preprocessed_train_3.csv\", index_col=0)\n",
    "test_data = pd.read_csv(\"preprocessed_test_3.csv\", index_col=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"change_type\"\n",
    "X = train_data.drop(columns = target)\n",
    "Y = train_data[target].map({'Demolition': 0, 'Road': 1, 'Residential': 2, 'Commercial': 3, 'Industrial': 4,\n",
    "       'Mega Projects': 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Giga Classifier : The one to gather all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "def new_sampling(X, y, strategy):\n",
    "    strat_under = {}\n",
    "\n",
    "    for cat, nb in strategy.items():\n",
    "        if nb < np.unique(y, return_counts=True)[1][cat]:\n",
    "            strat_under[cat] = nb\n",
    "        else : \n",
    "            strat_under[cat] = np.unique(y, return_counts=True)[1][cat]\n",
    "    X, y = RandomUnderSampler(sampling_strategy=strat_under).fit_resample(X, y)\n",
    "    X, y = RandomOverSampler(sampling_strategy=strategy).fit_resample(X, y)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "class GigaClassifier(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, **params):\n",
    "        self.params = params\n",
    "\n",
    "        if \"param_class0\" in params.keys():\n",
    "            self.clf0 = LGBMClassifier(**params[\"param_class0\"])\n",
    "        else :\n",
    "            self.clf0 = LGBMClassifier()\n",
    "        \n",
    "        if \"param_class1\" in params.keys():\n",
    "            self.clf1 = LGBMClassifier(**params[\"param_class1\"])\n",
    "        else :\n",
    "            self.clf1 = LGBMClassifier()\n",
    "\n",
    "        if \"param_class2\" in params.keys():\n",
    "            self.clf2 = LGBMClassifier(**params[\"param_class2\"])\n",
    "        else :\n",
    "            self.clf2 = LGBMClassifier()\n",
    "\n",
    "        if \"param_class3\" in params.keys():\n",
    "            self.clf3 = LGBMClassifier(**params[\"param_class3\"])\n",
    "        else :\n",
    "            self.clf3 = LGBMClassifier()\n",
    "\n",
    "        if \"param_class4\" in params.keys():\n",
    "            self.clf4 = LGBMClassifier(**params[\"param_class4\"])\n",
    "        else :\n",
    "            self.clf4 = LGBMClassifier()\n",
    "\n",
    "        if \"param_class5\" in params.keys():\n",
    "            self.clf5 = LGBMClassifier(**params[\"param_class5\"])\n",
    "        else :\n",
    "            self.clf5 = LGBMClassifier()\n",
    "\n",
    "        if \"param_class23\" in params.keys():\n",
    "            self.clf23 = LGBMClassifier(**params[\"param_class23\"])\n",
    "        else :\n",
    "            self.clf23 = LGBMClassifier()\n",
    "\n",
    "        if \"param_class02\" in params.keys():\n",
    "            self.clf02 = LGBMClassifier(**params[\"param_class02\"])\n",
    "        else:\n",
    "            self.clf02 = LGBMClassifier()\n",
    "\n",
    "        if \"param_class_final\" in params.keys():\n",
    "            self.clf_final = LogisticRegression(**params[\"param_class_final\"])\n",
    "        else :\n",
    "            self.clf_final = LogisticRegression()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X, _ = check_X_y(X, y)\n",
    "        \n",
    "        self.classes_ = unique_labels(y)\n",
    "\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "    \n",
    "        _, n = np.unique(self.y_, return_counts=True)\n",
    "        \n",
    "        # Classifier 0\n",
    "\n",
    "        if \"strategy0\" in self.params.keys():\n",
    "            strategy = self.params[\"strategy0\"]\n",
    "            print('ok')\n",
    "        else :\n",
    "            k = n[0]*4\n",
    "            strategy = {0 : k, 1 : int(k/5), 2 : int(k/5), 3 : int(k/5), 4 : int(k/5), 5 : int(k/5)}\n",
    "\n",
    "        X_train0, y_train0 = new_sampling(self.X_, self.y_, strategy)\n",
    "        y_train0 = y_train0.apply(lambda x : 1 if x == 0 else 0)\n",
    "\n",
    "        self.clf0 = self.clf0.fit(X_train0, y_train0)\n",
    "\n",
    "        del X_train0\n",
    "        del y_train0\n",
    "\n",
    "        # Classifier 1\n",
    "        if \"strategy1\" in self.params.keys():\n",
    "            strategy = self.params[\"strategy1\"]\n",
    "        else :\n",
    "            k = n[1]*7\n",
    "            strategy = {0 : int(k/5), 1 : k, 2 : int(k/5), 3 : int(k/5), 4 : int(k/5), 5 : int(k/5)}\n",
    "\n",
    "        X_train1, y_train1 = new_sampling(self.X_, self.y_, strategy)\n",
    "        y_train1 = y_train1.apply(lambda x : 1 if x == 1 else 0)\n",
    "\n",
    "        self.clf1 = self.clf1.fit(X_train1, y_train1)\n",
    "\n",
    "        del X_train1\n",
    "        del y_train1\n",
    "        \n",
    "        # Classifier 2\n",
    "\n",
    "        if \"strategy2\" in self.params.keys():\n",
    "            strategy = self.params[\"strategy2\"]\n",
    "        else :\n",
    "            k = n[2]//2\n",
    "            strategy = {0 : int(k/5), 1 : int(k/5), 2 : k, 3 : int(k/5), 4 : int(k/5), 5 : int(k/5)}\n",
    "\n",
    "        X_train2, y_train2 = new_sampling(self.X_, self.y_, strategy)\n",
    "        y_train2 = y_train2.apply(lambda x : 1 if x == 2 else 0)\n",
    "\n",
    "        self.clf2 = self.clf2.fit(X_train2, y_train2)\n",
    "\n",
    "        del X_train2\n",
    "        del y_train2\n",
    "        \n",
    "        # Classifier 3\n",
    "        if \"strategy3\" in self.params.keys():\n",
    "            strategy = self.params[\"strategy3\"]\n",
    "        else :\n",
    "            k = n[3]\n",
    "            strategy = {0 : int(k/5), 1 : int(k/5), 2 : int(k/5), 3 : k, 4 : int(k/5), 5 : int(k/5)}\n",
    "\n",
    "        X_train3, y_train3 = new_sampling(self.X_, self.y_, strategy)\n",
    "        y_train3 = y_train3.apply(lambda x : 1 if x == 3 else 0)\n",
    "\n",
    "        self.clf3 = self.clf3.fit(X_train3, y_train3)\n",
    "\n",
    "        del X_train3\n",
    "        del y_train3\n",
    "        \n",
    "        # Classifier 4\n",
    "        if \"strategy4\" in self.params.keys():\n",
    "            strategy = self.params[\"strategy4\"]\n",
    "        else :\n",
    "            k = n[4]*15\n",
    "            strategy = {0 : int(k/5), 1 : int(k/5), 2 : int(k/5), 3 : int(k/5), 4 : k, 5 : int(k/5)}\n",
    "        X_train4, y_train4 = new_sampling(self.X_, self.y_, strategy)\n",
    "        y_train4 = y_train4.apply(lambda x : 1 if x == 4 else 0)\n",
    "\n",
    "        self.clf4 = self.clf4.fit(X_train4, y_train4)\n",
    "\n",
    "        del X_train4\n",
    "        del y_train4\n",
    "        \n",
    "        # Classifier 5\n",
    "        if \"strategy5\" in self.params.keys():\n",
    "            strategy = self.params[\"strategy5\"]\n",
    "        else :\n",
    "            k = n[5]*30\n",
    "            strategy = {0 : int(k/5), 1 : int(k/5), 2 : int(k/5), 3 : int(k/5), 4 : int(k/5), 5 : k}\n",
    "\n",
    "        X_train5, y_train5 = new_sampling(self.X_, self.y_, strategy)\n",
    "        y_train5 = y_train5.apply(lambda x : 1 if x == 5 else 0)\n",
    "\n",
    "        self.clf5 = self.clf5.fit(X_train5, y_train5)\n",
    "\n",
    "        del X_train5\n",
    "        del y_train5\n",
    "\n",
    "        # Classifier 2-3\n",
    "\n",
    "        mask = (self.y_ >= 2)&(self.y_ <= 3)\n",
    "        X_train_23 = self.X_[mask]\n",
    "        y_train_23 = self.y_[mask].apply(lambda x : 0 if x == 2 else 1)\n",
    "\n",
    "        self.clf23.fit(X_train_23, y_train_23)\n",
    "\n",
    "        del X_train_23\n",
    "        del y_train_23\n",
    "\n",
    "        # Classifier 0-2\n",
    "\n",
    "        mask = (self.y_ == 0) | (self.y_ == 2)\n",
    "        X_train_02 = self.X_[mask]\n",
    "        y_train_02 = self.y_[mask].apply(lambda x : 1 if x == 2 else 0)\n",
    "\n",
    "        self.clf02.fit(X_train_02, y_train_02)\n",
    "\n",
    "        del X_train_02\n",
    "        del y_train_02\n",
    "\n",
    "\n",
    "        # # Final classifier\n",
    "\n",
    "        self.clf_final.fit(np.array([self.clf0.predict_proba(self.X_)[:, 1], self.clf1.predict_proba(self.X_)[:, 1], self.clf2.predict_proba(self.X_)[:, 1], self.clf3.predict_proba(self.X_)[:, 1], self.clf4.predict_proba(self.X_)[:, 1], self.clf5.predict_proba(self.X_)[:, 1], self.clf23.predict_proba(self.X_)[:, 1], self.clf02.predict_proba(self.X_)[:, 1]]).T, self.y_)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        check_is_fitted(self)\n",
    "        X = check_array(X)\n",
    "\n",
    "        y_pred = self.clf_final.predict(np.array([self.clf0.predict_proba(X)[:, 1], self.clf1.predict_proba(X)[:, 1], self.clf2.predict_proba(X)[:, 1], self.clf3.predict_proba(X)[:, 1], self.clf4.predict_proba(X)[:, 1], self.clf5.predict_proba(X)[:, 1], self.clf23.predict_proba(X)[:, 1], self.clf02.predict_proba(X)[:, 1]]).T)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some errors from the computer made some issue with the data.\n",
    "# It comes from nowhere ...\n",
    "\n",
    "X_train = np.nan_to_num(X_train)\n",
    "X_test = np.nan_to_num(X_test)\n",
    "test_data = np.nan_to_num(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Optimisation of the sampling strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "\n",
    "    strategy0 = {\n",
    "                      0: trial.suggest_int(\"k_0_0\", 100, 70000),\n",
    "                      1: trial.suggest_int(\"k_1_0\", 100, 70000),\n",
    "                      2: trial.suggest_int(\"k_2_0\", 100, 70000),\n",
    "                      3: trial.suggest_int(\"k_3_0\", 100, 70000),\n",
    "                      4: trial.suggest_int(\"k_4_0\", 100, 70000),\n",
    "                      5: trial.suggest_int(\"k_5_0\", 100, 15000),\n",
    "\n",
    "\n",
    "    }\n",
    "\n",
    "    strategy1 = {\n",
    "                      0: trial.suggest_int(\"k_0_1\", 100, 70000),\n",
    "                      1: trial.suggest_int(\"k_1_1\", 100, 70000),\n",
    "                      2: trial.suggest_int(\"k_2_1\", 100, 70000),\n",
    "                      3: trial.suggest_int(\"k_3_1\", 100, 70000),\n",
    "                      4: trial.suggest_int(\"k_4_1\", 100, 70000),\n",
    "                      5: trial.suggest_int(\"k_5_1\", 100, 15000),\n",
    "\n",
    "    }\n",
    "\n",
    "    strategy2 = {\n",
    "                      0: trial.suggest_int(\"k_0_2\", 100, 70000),\n",
    "                      1: trial.suggest_int(\"k_1_2\", 100, 70000),\n",
    "                      2: trial.suggest_int(\"k_2_2\", 100, 70000),\n",
    "                      3: trial.suggest_int(\"k_3_2\", 100, 70000),\n",
    "                      4: trial.suggest_int(\"k_4_2\", 100, 70000),\n",
    "                      5: trial.suggest_int(\"k_5_2\", 100, 15000),\n",
    "\n",
    "    }\n",
    "\n",
    "    strategy3 = {\n",
    "                      0: trial.suggest_int(\"k_0_3\", 100, 70000),\n",
    "                      1: trial.suggest_int(\"k_1_3\", 100, 70000),\n",
    "                      2: trial.suggest_int(\"k_2_3\", 100, 70000),\n",
    "                      3: trial.suggest_int(\"k_3_3\", 100, 70000),\n",
    "                      4: trial.suggest_int(\"k_4_3\", 100, 70000),\n",
    "                      5: trial.suggest_int(\"k_5_3\", 100, 15000),\n",
    "\n",
    "    }\n",
    "\n",
    "    strategy4 = {\n",
    "                      0: trial.suggest_int(\"k_0_4\", 100, 70000),\n",
    "                      1: trial.suggest_int(\"k_1_4\", 100, 70000),\n",
    "                      2: trial.suggest_int(\"k_2_4\", 100, 70000),\n",
    "                      3: trial.suggest_int(\"k_3_4\", 100, 70000),\n",
    "                      4: trial.suggest_int(\"k_4_4\", 100, 70000),\n",
    "                      5: trial.suggest_int(\"k_5_4\", 100, 15000),\n",
    "\n",
    "    }\n",
    "\n",
    "    strategy5 = {\n",
    "                      0: trial.suggest_int(\"k_0_5\", 100, 70000),\n",
    "                      1: trial.suggest_int(\"k_1_5\", 100, 70000),\n",
    "                      2: trial.suggest_int(\"k_2_5\", 100, 70000),\n",
    "                      3: trial.suggest_int(\"k_3_5\", 100, 70000),\n",
    "                      4: trial.suggest_int(\"k_4_5\", 100, 70000),\n",
    "                      5: trial.suggest_int(\"k_5_5\", 100, 15000),\n",
    "    }\n",
    "\n",
    "    \n",
    " \n",
    "    param = {'strategy0' : strategy0, 'strategy1' : strategy1, 'strategy2' : strategy2, \n",
    "             'strategy3' : strategy3, 'strategy4' : strategy4, 'strategy5' : strategy5,\n",
    "             }\n",
    "    Giga = GigaClassifier(param=param).fit(X_train, y_train)\n",
    "    preds = Giga.predict(X_test)\n",
    "    score = 0.8*f1_score(y_test, preds, average='micro') + 0.2*0.8*f1_score(y_test, preds, average='macro')\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> New parameters from another optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params0 = {\n",
    "    'lambda_l1': 8.065393401857228e-06,\n",
    "    'lambda_l2': 0.029803367056138796,\n",
    "    'num_leaves': 190,\n",
    "    'feature_fraction': 0.797014941354135,\n",
    "    'bagging_fraction': 0.6056293592061583,\n",
    "    'bagging_freq': 6,\n",
    "    'min_child_samples': 35,\n",
    "}\n",
    "params1 = {\n",
    "    'lambda_l1': 0.0014150936181843796,\n",
    "    'lambda_l2': 0.015200649198535246,\n",
    "    'num_leaves': 213,\n",
    "    'feature_fraction': 0.6891955399281373,\n",
    "    'bagging_fraction': 0.6304609421580529,\n",
    "    'bagging_freq': 3,\n",
    "    'min_child_samples': 78,\n",
    "}\n",
    "params2 = {\n",
    "    'lambda_l1': 0.00043925265669491026,\n",
    "    'lambda_l2': 9.479211152048597e-08,\n",
    "    'num_leaves': 216,\n",
    "    'feature_fraction': 0.5456789734159285,\n",
    "    'bagging_fraction': 0.699812579931553,\n",
    "    'bagging_freq': 1,\n",
    "    'min_child_samples': 93,\n",
    "}\n",
    "params3 = {\n",
    "    'lambda_l1': 0.01636000817108605,\n",
    "    'lambda_l2': 0.1681160879676377,\n",
    "    'num_leaves': 82,\n",
    "    'feature_fraction': 0.5035311652439594,\n",
    "    'bagging_fraction': 0.6759265334335514,\n",
    "    'bagging_freq': 5,\n",
    "    'min_child_samples': 93,\n",
    "}\n",
    "params4 = {\n",
    "    'lambda_l1': 3.23091933287523e-05,\n",
    "    'lambda_l2': 1.576373921261149,\n",
    "    'num_leaves': 81,\n",
    "    'feature_fraction': 0.9004686195418676,\n",
    "    'bagging_fraction': 0.5815720681139029,\n",
    "    'bagging_freq': 1,\n",
    "    'min_child_samples': 21,\n",
    "}\n",
    "params5 = {\n",
    "    'lambda_l1': 7.3489291515387846e-06,\n",
    "    'lambda_l2': 8.823411285304899e-08,\n",
    "    'num_leaves': 212,\n",
    "    'feature_fraction': 0.6363314441863244,\n",
    "    'bagging_fraction':  0.48949866504397654,\n",
    "    'bagging_freq': 5,\n",
    "    'min_child_samples': 38,\n",
    "}\n",
    "params23 = {\n",
    "    'lambda_l1': .1279932407823657e-07,\n",
    "    'lambda_l2': 9.707107657903811e-07,\n",
    "    'num_leaves': 3,\n",
    "    'feature_fraction': 0.5895943660453787,\n",
    "    'bagging_fraction': 0.4995724225169822,\n",
    "    'bagging_freq': 7,\n",
    "    'min_child_samples': 65,\n",
    "}\n",
    "strategy0 = {\n",
    "    0 : 66269,\n",
    "    1 : 47889,\n",
    "    2 : 1300,\n",
    "    3 : 59972,\n",
    "    4 : 27613,\n",
    "    5 : 4831,\n",
    "}\n",
    "strategy1 = {\n",
    "    0 : 22202,\n",
    "    1 : 63926,\n",
    "    2 : 49998,\n",
    "    3 : 20079,\n",
    "    4 : 49417,\n",
    "    5 : 8442,\n",
    "}\n",
    "strategy2 = {\n",
    "    0 : 42206,\n",
    "    1 : 63036,\n",
    "    2 : 62078,\n",
    "    3 : 51447,\n",
    "    4 : 45821,\n",
    "    5 : 3484,\n",
    "}\n",
    "strategy3 = {\n",
    "    0 : 19449,\n",
    "    1 : 18530,\n",
    "    2 : 13774,\n",
    "    3 : 32118,\n",
    "    4 : 638,\n",
    "    5 : 7377,\n",
    "}\n",
    "strategy4 = {\n",
    "    0 : 48220,\n",
    "    1 : 51799,\n",
    "    2 : 9703,\n",
    "    3 : 63043,\n",
    "    4 : 4353,\n",
    "    5 : 12506,\n",
    "}\n",
    "strategy5 = {\n",
    "    0 : 46176,\n",
    "    1 : 39871,\n",
    "    2 : 52339,\n",
    "    3 : 62464,\n",
    "    4 : 51783,\n",
    "    5 : 11293,\n",
    "}\n",
    "\n",
    "model = GigaClassifier(param_class0 = params0, param_class1 = params1, param_class2 = params2,\n",
    "                       param_class3 = params3, param_class4 = params4, param_class5 = params5,\n",
    "                       param_class23 = params23, strategy0 = strategy0, strategy1 = strategy1,\n",
    "                       strategy2 = strategy2, strategy3 = strategy3, strategy4 = strategy4,\n",
    "                       strategy5 = strategy5)\n",
    "model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.76      0.83      8995\n",
      "           1       0.76      0.70      0.73      4054\n",
      "           2       0.78      0.83      0.81     38627\n",
      "           3       0.69      0.67      0.68     25583\n",
      "           4       0.13      0.20      0.16       238\n",
      "           5       0.07      0.40      0.12         5\n",
      "\n",
      "    accuracy                           0.76     77502\n",
      "   macro avg       0.56      0.59      0.55     77502\n",
      "weighted avg       0.76      0.76      0.76     77502\n",
      "\n",
      "[[ 6811    27  1482   665     9     1]\n",
      " [   38  2844   338   820    13     1]\n",
      " [  197   149 32023  6161    87    10]\n",
      " [  386   732  7002 17238   211    14]\n",
      " [    2     3    77   107    48     1]\n",
      " [    0     1     0     1     1     2]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "cf_matrix = confusion_matrix(y_pred, y_test)\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121704,)\n"
     ]
    }
   ],
   "source": [
    "# For submission\n",
    "\n",
    "y_pred_final = model.predict(test_data)\n",
    "print(y_pred_final.shape)\n",
    "\n",
    "pred_df = pd.DataFrame(y_pred_final, columns=['change_type'])\n",
    "pred_df.to_csv(\"submissions/raph_sample_submission.csv\", index=True, index_label='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Global optimisation on micro f1-score and Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "def new_sampling(X, y, strategy):\n",
    "    strat_under = {}\n",
    "\n",
    "    for cat, nb in strategy.items():\n",
    "        if nb < np.unique(y, return_counts=True)[1][cat]:\n",
    "            strat_under[cat] = nb\n",
    "        else : \n",
    "            strat_under[cat] = np.unique(y, return_counts=True)[1][cat]\n",
    "    X, y = RandomUnderSampler(sampling_strategy=strat_under).fit_resample(X, y)\n",
    "    X, y = RandomOverSampler(sampling_strategy=strategy).fit_resample(X, y)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "class GigaClassifier(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, **params):\n",
    "        self.params = params\n",
    "\n",
    "        if \"param_class0\" in params.keys():\n",
    "            self.clf0 = LGBMClassifier(**params[\"param_class0\"])\n",
    "        else :\n",
    "            self.clf0 = LGBMClassifier()\n",
    "        \n",
    "        if \"param_class1\" in params.keys():\n",
    "            self.clf1 = LGBMClassifier(**params[\"param_class1\"])\n",
    "        else :\n",
    "            self.clf1 = LGBMClassifier()\n",
    "\n",
    "        if \"param_class2\" in params.keys():\n",
    "            self.clf2 = LGBMClassifier(**params[\"param_class2\"])\n",
    "        else :\n",
    "            self.clf2 = LGBMClassifier()\n",
    "\n",
    "        if \"param_class3\" in params.keys():\n",
    "            self.clf3 = LGBMClassifier(**params[\"param_class3\"])\n",
    "        else :\n",
    "            self.clf3 = LGBMClassifier()\n",
    "\n",
    "        if \"param_class4\" in params.keys():\n",
    "            self.clf4 = LGBMClassifier(**params[\"param_class4\"])\n",
    "        else :\n",
    "            self.clf4 = LGBMClassifier()\n",
    "\n",
    "        if \"param_class5\" in params.keys():\n",
    "            self.clf5 = LGBMClassifier(**params[\"param_class5\"])\n",
    "        else :\n",
    "            self.clf5 = LGBMClassifier()\n",
    "\n",
    "        if \"param_class23\" in params.keys():\n",
    "            self.clf23 = LGBMClassifier(**params[\"param_class23\"])\n",
    "        else :\n",
    "            self.clf23 = LGBMClassifier()\n",
    "\n",
    "        if \"param_class02\" in params.keys():\n",
    "            self.clf02 = LGBMClassifier(**params[\"param_class02\"])\n",
    "        else:\n",
    "            self.clf02 = LGBMClassifier()\n",
    "\n",
    "        if \"param_class_final\" in params.keys():\n",
    "            self.clf_final = LogisticRegressionCV(cv = 5, **params[\"param_class_final\"])\n",
    "        else :\n",
    "            self.clf_final = LogisticRegressionCV(cv = 5)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X, _ = check_X_y(X, y)\n",
    "        \n",
    "        self.classes_ = unique_labels(y)\n",
    "\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "    \n",
    "        _, n = np.unique(self.y_, return_counts=True)\n",
    "        \n",
    "        # Classifier 0\n",
    "\n",
    "        if \"strategy0\" in self.params.keys():\n",
    "            strategy = self.params[\"strategy0\"]\n",
    "            print('ok')\n",
    "        else :\n",
    "            k = n[0]*4\n",
    "            strategy = {0 : k, 1 : int(k/5), 2 : int(k/5), 3 : int(k/5), 4 : int(k/5), 5 : int(k/5)}\n",
    "\n",
    "        X_train0, y_train0 = new_sampling(self.X_, self.y_, strategy)\n",
    "        y_train0 = y_train0.apply(lambda x : 1 if x == 0 else 0)\n",
    "\n",
    "        self.clf0 = self.clf0.fit(X_train0, y_train0)\n",
    "\n",
    "        del X_train0\n",
    "        del y_train0\n",
    "\n",
    "        # Classifier 1\n",
    "        if \"strategy1\" in self.params.keys():\n",
    "            strategy = self.params[\"strategy1\"]\n",
    "        else :\n",
    "            k = n[1]*7\n",
    "            strategy = {0 : int(k/5), 1 : k, 2 : int(k/5), 3 : int(k/5), 4 : int(k/5), 5 : int(k/5)}\n",
    "\n",
    "        X_train1, y_train1 = new_sampling(self.X_, self.y_, strategy)\n",
    "        y_train1 = y_train1.apply(lambda x : 1 if x == 1 else 0)\n",
    "\n",
    "        self.clf1 = self.clf1.fit(X_train1, y_train1)\n",
    "\n",
    "        del X_train1\n",
    "        del y_train1\n",
    "        \n",
    "        # Classifier 2\n",
    "\n",
    "        if \"strategy2\" in self.params.keys():\n",
    "            strategy = self.params[\"strategy2\"]\n",
    "        else :\n",
    "            k = n[2]//2\n",
    "            strategy = {0 : int(k/5), 1 : int(k/5), 2 : k, 3 : int(k/5), 4 : int(k/5), 5 : int(k/5)}\n",
    "\n",
    "        X_train2, y_train2 = new_sampling(self.X_, self.y_, strategy)\n",
    "        y_train2 = y_train2.apply(lambda x : 1 if x == 2 else 0)\n",
    "\n",
    "        self.clf2 = self.clf2.fit(X_train2, y_train2)\n",
    "\n",
    "        del X_train2\n",
    "        del y_train2\n",
    "        \n",
    "        # Classifier 3\n",
    "        if \"strategy3\" in self.params.keys():\n",
    "            strategy = self.params[\"strategy3\"]\n",
    "        else :\n",
    "            k = n[3]\n",
    "            strategy = {0 : int(k/5), 1 : int(k/5), 2 : int(k/5), 3 : k, 4 : int(k/5), 5 : int(k/5)}\n",
    "\n",
    "        X_train3, y_train3 = new_sampling(self.X_, self.y_, strategy)\n",
    "        y_train3 = y_train3.apply(lambda x : 1 if x == 3 else 0)\n",
    "\n",
    "        self.clf3 = self.clf3.fit(X_train3, y_train3)\n",
    "\n",
    "        del X_train3\n",
    "        del y_train3\n",
    "        \n",
    "        # Classifier 4\n",
    "        if \"strategy4\" in self.params.keys():\n",
    "            strategy = self.params[\"strategy4\"]\n",
    "        else :\n",
    "            k = n[4]*15\n",
    "            strategy = {0 : int(k/5), 1 : int(k/5), 2 : int(k/5), 3 : int(k/5), 4 : k, 5 : int(k/5)}\n",
    "        X_train4, y_train4 = new_sampling(self.X_, self.y_, strategy)\n",
    "        y_train4 = y_train4.apply(lambda x : 1 if x == 4 else 0)\n",
    "\n",
    "        self.clf4 = self.clf4.fit(X_train4, y_train4)\n",
    "\n",
    "        del X_train4\n",
    "        del y_train4\n",
    "        \n",
    "        # Classifier 5\n",
    "        if \"strategy5\" in self.params.keys():\n",
    "            strategy = self.params[\"strategy5\"]\n",
    "        else :\n",
    "            k = n[5]*30\n",
    "            strategy = {0 : int(k/5), 1 : int(k/5), 2 : int(k/5), 3 : int(k/5), 4 : int(k/5), 5 : k}\n",
    "\n",
    "        X_train5, y_train5 = new_sampling(self.X_, self.y_, strategy)\n",
    "        y_train5 = y_train5.apply(lambda x : 1 if x == 5 else 0)\n",
    "\n",
    "        self.clf5 = self.clf5.fit(X_train5, y_train5)\n",
    "\n",
    "        del X_train5\n",
    "        del y_train5\n",
    "\n",
    "        # Classifier 2-3\n",
    "\n",
    "        mask = (self.y_ >= 2)&(self.y_ <= 3)\n",
    "        X_train_23 = self.X_[mask]\n",
    "        y_train_23 = self.y_[mask].apply(lambda x : 0 if x == 2 else 1)\n",
    "\n",
    "        self.clf23.fit(X_train_23, y_train_23)\n",
    "\n",
    "        del X_train_23\n",
    "        del y_train_23\n",
    "\n",
    "        # Classifier 0-2\n",
    "\n",
    "        mask = (self.y_ == 0) | (self.y_ == 2)\n",
    "        X_train_02 = self.X_[mask]\n",
    "        y_train_02 = self.y_[mask].apply(lambda x : 1 if x == 2 else 0)\n",
    "\n",
    "        self.clf02.fit(X_train_02, y_train_02)\n",
    "\n",
    "        del X_train_02\n",
    "        del y_train_02\n",
    "\n",
    "\n",
    "        # # Final classifier\n",
    "\n",
    "        self.clf_final.fit(np.array([self.clf0.predict_proba(self.X_)[:, 1], self.clf1.predict_proba(self.X_)[:, 1], self.clf2.predict_proba(self.X_)[:, 1], self.clf3.predict_proba(self.X_)[:, 1], self.clf4.predict_proba(self.X_)[:, 1], self.clf5.predict_proba(self.X_)[:, 1], self.clf23.predict_proba(self.X_)[:, 1], self.clf02.predict_proba(self.X_)[:, 1]]).T, self.y_)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        check_is_fitted(self)\n",
    "        X = check_array(X)\n",
    "\n",
    "        y_pred = self.clf_final.predict(np.array([self.clf0.predict_proba(X)[:, 1], self.clf1.predict_proba(X)[:, 1], self.clf2.predict_proba(X)[:, 1], self.clf3.predict_proba(X)[:, 1], self.clf4.predict_proba(X)[:, 1], self.clf5.predict_proba(X)[:, 1], self.clf23.predict_proba(X)[:, 1], self.clf02.predict_proba(X)[:, 1]]).T)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "    param_class0 = {\n",
    "                      \"objective\": \"binary\",\n",
    "                      \"metric\": \"binary_logloss\",\n",
    "                      \"verbosity\": -1,\n",
    "                      \"boosting_type\": \"gbdt\",\n",
    "                      \"lambda_l1\": trial.suggest_float(\"lambda_l1_0\", 1e-8, 10.0, log=True),\n",
    "                      \"lambda_l2\": trial.suggest_float(\"lambda_l2_0\", 1e-8, 10.0, log=True),\n",
    "                      \"num_leaves\": trial.suggest_int(\"num_leaves_0\", 2, 256),\n",
    "                      \"feature_fraction\": trial.suggest_float(\"feature_fraction_0\", 0.4, 1.0),\n",
    "                      \"bagging_fraction\": trial.suggest_float(\"bagging_fraction_0\", 0.4, 1.0),\n",
    "                      \"bagging_freq\": trial.suggest_int(\"bagging_freq_0\", 1, 7),\n",
    "                      \"min_child_samples\": trial.suggest_int(\"min_child_samples_0\", 5, 100),\n",
    "    }\n",
    "\n",
    "    param_class1 = {\n",
    "                      \"objective\": \"binary\",\n",
    "                      \"metric\": \"binary_logloss\",\n",
    "                      \"verbosity\": -1,\n",
    "                      \"boosting_type\": \"gbdt\",\n",
    "                      \"lambda_l1\": trial.suggest_float(\"lambda_l1_1\", 1e-8, 10.0, log=True),\n",
    "                      \"lambda_l2\": trial.suggest_float(\"lambda_l2_1\", 1e-8, 10.0, log=True),\n",
    "                      \"num_leaves\": trial.suggest_int(\"num_leaves_1\", 2, 256),\n",
    "                      \"feature_fraction\": trial.suggest_float(\"feature_fraction_1\", 0.4, 1.0),\n",
    "                      \"bagging_fraction\": trial.suggest_float(\"bagging_fraction_1\", 0.4, 1.0),\n",
    "                      \"bagging_freq\": trial.suggest_int(\"bagging_freq_1\", 1, 7),\n",
    "                      \"min_child_samples\": trial.suggest_int(\"min_child_samples_1\", 5, 100),\n",
    "    }\n",
    "\n",
    "    param_class2 = {\n",
    "                      \"objective\": \"binary\",\n",
    "                      \"metric\": \"binary_logloss\",\n",
    "                      \"verbosity\": -1,\n",
    "                      \"boosting_type\": \"gbdt\",\n",
    "                      \"lambda_l1\": trial.suggest_float(\"lambda_l1_2\", 1e-8, 10.0, log=True),\n",
    "                      \"lambda_l2\": trial.suggest_float(\"lambda_l2_2\", 1e-8, 10.0, log=True),\n",
    "                      \"num_leaves\": trial.suggest_int(\"num_leaves_2\", 2, 256),\n",
    "                      \"feature_fraction\": trial.suggest_float(\"feature_fraction_2\", 0.4, 1.0),\n",
    "                      \"bagging_fraction\": trial.suggest_float(\"bagging_fraction_2\", 0.4, 1.0),\n",
    "                      \"bagging_freq\": trial.suggest_int(\"bagging_freq_2\", 1, 7),\n",
    "                      \"min_child_samples\": trial.suggest_int(\"min_child_samples_2\", 5, 100),\n",
    "    }\n",
    "\n",
    "    param_class3 = {\n",
    "                      \"objective\": \"binary\",\n",
    "                      \"metric\": \"binary_logloss\",\n",
    "                      \"verbosity\": -1,\n",
    "                      \"boosting_type\": \"gbdt\",\n",
    "                      \"lambda_l1\": trial.suggest_float(\"lambda_l1_3\", 1e-8, 10.0, log=True),\n",
    "                      \"lambda_l2\": trial.suggest_float(\"lambda_l2_3\", 1e-8, 10.0, log=True),\n",
    "                      \"num_leaves\": trial.suggest_int(\"num_leaves_3\", 2, 256),\n",
    "                      \"feature_fraction\": trial.suggest_float(\"feature_fraction_3\", 0.4, 1.0),\n",
    "                      \"bagging_fraction\": trial.suggest_float(\"bagging_fraction_3\", 0.4, 1.0),\n",
    "                      \"bagging_freq\": trial.suggest_int(\"bagging_freq_3\", 1, 7),\n",
    "                      \"min_child_samples\": trial.suggest_int(\"min_child_samples_3\", 5, 100),\n",
    "    }\n",
    "\n",
    "    param_class4 = {\n",
    "                      \"objective\": \"binary\",\n",
    "                      \"metric\": \"binary_logloss\",\n",
    "                      \"verbosity\": -1,\n",
    "                      \"boosting_type\": \"gbdt\",\n",
    "                      \"lambda_l1\": trial.suggest_float(\"lambda_l1_4\", 1e-8, 10.0, log=True),\n",
    "                      \"lambda_l2\": trial.suggest_float(\"lambda_l2_4\", 1e-8, 10.0, log=True),\n",
    "                      \"num_leaves\": trial.suggest_int(\"num_leaves_4\", 2, 256),\n",
    "                      \"feature_fraction\": trial.suggest_float(\"feature_fraction_4\", 0.4, 1.0),\n",
    "                      \"bagging_fraction\": trial.suggest_float(\"bagging_fraction_4\", 0.4, 1.0),\n",
    "                      \"bagging_freq\": trial.suggest_int(\"bagging_freq_4\", 1, 7),\n",
    "                      \"min_child_samples\": trial.suggest_int(\"min_child_samples_4\", 5, 100),\n",
    "    }\n",
    "\n",
    "    param_class5 = {\n",
    "                      \"objective\": \"binary\",\n",
    "                      \"metric\": \"binary_logloss\",\n",
    "                      \"verbosity\": -1,\n",
    "                      \"boosting_type\": \"gbdt\",\n",
    "                      \"lambda_l1\": trial.suggest_float(\"lambda_l1_5\", 1e-8, 10.0, log=True),\n",
    "                      \"lambda_l2\": trial.suggest_float(\"lambda_l2_5\", 1e-8, 10.0, log=True),\n",
    "                      \"num_leaves\": trial.suggest_int(\"num_leaves_5\", 2, 256),\n",
    "                      \"feature_fraction\": trial.suggest_float(\"feature_fraction_5\", 0.4, 1.0),\n",
    "                      \"bagging_fraction\": trial.suggest_float(\"bagging_fraction_5\", 0.4, 1.0),\n",
    "                      \"bagging_freq\": trial.suggest_int(\"bagging_freq_5\", 1, 7),\n",
    "                      \"min_child_samples\": trial.suggest_int(\"min_child_samples_5\", 5, 100),\n",
    "    }\n",
    "\n",
    "    param_class23 = {\n",
    "                      \"objective\": \"binary\",\n",
    "                      \"metric\": \"binary_logloss\",\n",
    "                      \"verbosity\": -1,\n",
    "                      \"boosting_type\": \"gbdt\",\n",
    "                      \"lambda_l1\": trial.suggest_float(\"lambda_l1_6\", 1e-8, 10.0, log=True),\n",
    "                      \"lambda_l2\": trial.suggest_float(\"lambda_l2_6\", 1e-8, 10.0, log=True),\n",
    "                      \"num_leaves\": trial.suggest_int(\"num_leaves_6\", 2, 256),\n",
    "                      \"feature_fraction\": trial.suggest_float(\"feature_fraction_6\", 0.4, 1.0),\n",
    "                      \"bagging_fraction\": trial.suggest_float(\"bagging_fraction_6\", 0.4, 1.0),\n",
    "                      \"bagging_freq\": trial.suggest_int(\"bagging_freq_6\", 1, 7),\n",
    "                      \"min_child_samples\": trial.suggest_int(\"min_child_samples_6\", 5, 100),\n",
    "    }\n",
    "\n",
    "    strategy0 = {\n",
    "                      0: trial.suggest_int(\"k_0_0\", 100, 40000),\n",
    "                      1: trial.suggest_int(\"k_1_0\", 100, 20000),\n",
    "                      2: trial.suggest_int(\"k_2_0\", 100, 120000),\n",
    "                      3: trial.suggest_int(\"k_3_0\", 100, 70000),\n",
    "                      4: trial.suggest_int(\"k_4_0\", 100, 15000),\n",
    "                      5: trial.suggest_int(\"k_5_0\", 100, 8000),\n",
    "\n",
    "\n",
    "    }\n",
    "\n",
    "    strategy1 = {\n",
    "                      0: trial.suggest_int(\"k_0_1\", 100, 40000),\n",
    "                      1: trial.suggest_int(\"k_1_1\", 100, 30000),\n",
    "                      2: trial.suggest_int(\"k_2_1\", 100, 12000),\n",
    "                      3: trial.suggest_int(\"k_3_1\", 100, 70000),\n",
    "                      4: trial.suggest_int(\"k_4_1\", 100, 15000),\n",
    "                      5: trial.suggest_int(\"k_5_1\", 100, 8000),\n",
    "\n",
    "    }\n",
    "\n",
    "    strategy2 = {\n",
    "                      0: trial.suggest_int(\"k_0_2\", 100, 40000),\n",
    "                      1: trial.suggest_int(\"k_1_2\", 100, 70000),\n",
    "                      2: trial.suggest_int(\"k_2_2\", 100, 120000),\n",
    "                      3: trial.suggest_int(\"k_3_2\", 100, 70000),\n",
    "                      4: trial.suggest_int(\"k_4_2\", 100, 15000),\n",
    "                      5: trial.suggest_int(\"k_5_2\", 100, 8000),\n",
    "\n",
    "    }\n",
    "\n",
    "    strategy3 = {\n",
    "                      0: trial.suggest_int(\"k_0_3\", 100, 40000),\n",
    "                      1: trial.suggest_int(\"k_1_3\", 100, 70000),\n",
    "                      2: trial.suggest_int(\"k_2_3\", 100, 120000),\n",
    "                      3: trial.suggest_int(\"k_3_3\", 100, 70000),\n",
    "                      4: trial.suggest_int(\"k_4_3\", 100, 18000),\n",
    "                      5: trial.suggest_int(\"k_5_3\", 100, 8000),\n",
    "\n",
    "    }\n",
    "\n",
    "    strategy4 = {\n",
    "                      0: trial.suggest_int(\"k_0_4\", 100, 40000),\n",
    "                      1: trial.suggest_int(\"k_1_4\", 100, 70000),\n",
    "                      2: trial.suggest_int(\"k_2_4\", 100, 70000),\n",
    "                      3: trial.suggest_int(\"k_3_4\", 100, 70000),\n",
    "                      4: trial.suggest_int(\"k_4_4\", 100, 15000),\n",
    "                      5: trial.suggest_int(\"k_5_4\", 100, 15000),\n",
    "\n",
    "    }\n",
    "\n",
    "    strategy5 = {\n",
    "                      0: trial.suggest_int(\"k_0_5\", 100, 40000),\n",
    "                      1: trial.suggest_int(\"k_1_5\", 100, 70000),\n",
    "                      2: trial.suggest_int(\"k_2_5\", 100, 120000),\n",
    "                      3: trial.suggest_int(\"k_3_5\", 100, 70000),\n",
    "                      4: trial.suggest_int(\"k_4_5\", 100, 70000),\n",
    "                      5: trial.suggest_int(\"k_5_5\", 100, 15000),\n",
    "    }\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "  \n",
    "    param = {'strategy0' : strategy0, 'strategy1' : strategy1, 'strategy2' : strategy2, \n",
    "             'strategy3' : strategy3, 'strategy4' : strategy4, 'strategy5' : strategy5,\n",
    "             'param_class0' : param_class0, 'param_class1' : param_class1, 'param_class2' : param_class2, \n",
    "             'param_class3' : param_class3, 'param_class4' : param_class4, 'param_class5' : param_class5,\n",
    "             'param_class23' : param_class23}\n",
    "    Giga = GigaClassifier(param=param).fit(X_train, y_train)\n",
    "    preds = Giga.predict(X_test)\n",
    "    score = f1_score(y_test, preds, average='micro')\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for best\n",
    "# 'lambda_l1_0': 2.622499162058228e-06, 'lambda_l2_0': 1.0238839304813224e-07, 'num_leaves_0': 199, 'feature_fraction_0': 0.411873339991237, 'bagging_fraction_0': 0.7445149277661633, 'bagging_freq_0': 6, 'min_child_samples_0': 6, 'lambda_l1_1': 0.025357166676963343, 'lambda_l2_1': 5.943170115391853, 'num_leaves_1': 146, 'feature_fraction_1': 0.8157016350444458, 'bagging_fraction_1': 0.8265957747327676, 'bagging_freq_1': 1, 'min_child_samples_1': 30, 'lambda_l1_2': 1.809784483494622e-05, 'lambda_l2_2': 1.7020746364298178e-07, 'num_leaves_2': 133, 'feature_fraction_2': 0.8695021268037981, 'bagging_fraction_2': 0.8113784925789771, 'bagging_freq_2': 2, 'min_child_samples_2': 11, 'lambda_l1_3': 3.0433742028157333e-07, 'lambda_l2_3': 7.646445515896699e-07, 'num_leaves_3': 178, 'feature_fraction_3': 0.7069056371794968, 'bagging_fraction_3': 0.5362513785909214, 'bagging_freq_3': 4, 'min_child_samples_3': 10, 'lambda_l1_4': 0.00012122778217885948, 'lambda_l2_4': 1.6084994046334085e-08, 'num_leaves_4': 89, 'feature_fraction_4': 0.5863990514141588, 'bagging_fraction_4': 0.8280470534097605, 'bagging_freq_4': 3, 'min_child_samples_4': 21, 'lambda_l1_5': 0.00026352973454501734, 'lambda_l2_5': 0.39486459136812085, 'num_leaves_5': 171, 'feature_fraction_5': 0.7678570870540501, 'bagging_fraction_5': 0.7153548983282392, 'bagging_freq_5': 4, 'min_child_samples_5': 16, 'lambda_l1_6': 1.4725187161289567e-08, 'lambda_l2_6': 0.0002608849372253336, 'num_leaves_6': 171, 'feature_fraction_6': 0.7230555773598342, 'bagging_fraction_6': 0.42025252466404367, 'bagging_freq_6': 7, 'min_child_samples_6': 53, 'k_0_0': 9128, 'k_1_0': 15203, 'k_2_0': 20815, 'k_3_0': 68450, 'k_4_0': 3996, 'k_5_0': 6126, 'k_0_1': 35047, 'k_1_1': 27669, 'k_2_1': 6503, 'k_3_1': 57595, 'k_4_1': 1195, 'k_5_1': 2326, 'k_0_2': 29559, 'k_1_2': 18637, 'k_2_2': 67956, 'k_3_2': 57930, 'k_4_2': 7156, 'k_5_2': 831, 'k_0_3': 26681, 'k_1_3': 38048, 'k_2_3': 101189, 'k_3_3': 59517, 'k_4_3': 848, 'k_5_3': 1967, 'k_0_4': 35086, 'k_1_4': 66236, 'k_2_4': 65599, 'k_3_4': 65815, 'k_4_4': 327, 'k_5_4': 2039, 'k_0_5': 39448, 'k_1_5': 41879, 'k_2_5': 105054, 'k_3_5': 36181, 'k_4_5': 8930, 'k_5_5': 7432\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
